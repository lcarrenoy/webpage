<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Engineer â€“ Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-dfb324f25d9b1687192fa8be62ac8f9c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Data Engineer</h1>
<p class="subtitle lead">100 Days to Become a Data Engineer</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="program-overview" class="level2">
<h2 class="anchored" data-anchor-id="program-overview">Program Overview</h2>
<p>This is an intensive 100-day program designed to train a Data Engineer from fundamentals to advanced projects. The plan includes key technologies, constant practice, and real-world projects.</p>
</section>
<section id="program-structure" class="level2">
<h2 class="anchored" data-anchor-id="program-structure">Program Structure</h2>
<section id="phase-1-fundamentals-days-1-13" class="level3">
<h3 class="anchored" data-anchor-id="phase-1-fundamentals-days-1-13">Phase 1: Fundamentals (Days 1-13)</h3>
<section id="sql---relational-databases-days-1-4" class="level4">
<h4 class="anchored" data-anchor-id="sql---relational-databases-days-1-4">SQL - Relational Databases (Days 1-4)</h4>
<ul>
<li><strong>Day 1</strong>: SQL introduction and basic commands (SELECT, FROM, WHERE)</li>
<li><strong>Day 2</strong>: Aggregation functions (SUM, AVG, COUNT), GROUP BY, HAVING, JOINs</li>
<li><strong>Day 3</strong>: Subqueries, CTEs, table creation, optimization</li>
<li><strong>Day 4</strong>: <strong>Practice</strong>: Database construction and complex queries</li>
</ul>
</section>
<section id="python-for-data-engineering-days-5-9" class="level4">
<h4 class="anchored" data-anchor-id="python-for-data-engineering-days-5-9">Python for Data Engineering (Days 5-9)</h4>
<ul>
<li><strong>Day 5</strong>: Basic syntax, variables, control structures</li>
<li><strong>Day 6</strong>: Functions, modules, file manipulation (CSV, TXT)</li>
<li><strong>Day 7</strong>: Exception handling, libraries (pandas, numpy, json, requests)</li>
<li><strong>Day 8</strong>: <strong>Practice</strong>: Data cleaning and transformation with pandas</li>
<li><strong>Day 9</strong>: <strong>Project</strong>: API data extraction and CSV storage</li>
</ul>
</section>
<section id="linux-and-bash-days-10-13" class="level4">
<h4 class="anchored" data-anchor-id="linux-and-bash-days-10-13">Linux and Bash (Days 10-13)</h4>
<ul>
<li><strong>Day 10</strong>: Linux basics, fundamental commands</li>
<li><strong>Day 11</strong>: Permissions, users, pipes, redirections, bash scripts, SSH</li>
<li><strong>Day 12</strong>: <strong>Practice</strong>: Cron jobs for periodic tasks</li>
<li><strong>Day 13</strong>: <strong>Practice</strong>: Bash script for file cleanup and organization</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/bin/bash</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Data processing bash script</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="va">LOG_DIR</span><span class="op">=</span><span class="st">"/var/log/data_pipeline"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="va">DATA_DIR</span><span class="op">=</span><span class="st">"/data/raw"</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="va">PROCESSED_DIR</span><span class="op">=</span><span class="st">"/data/processed"</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create log entry</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">log_message()</span> <span class="kw">{</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">echo</span> <span class="st">"</span><span class="va">$(</span><span class="fu">date</span><span class="va">)</span><span class="st">: </span><span class="va">$1</span><span class="st">"</span> <span class="op">&gt;&gt;</span> <span class="st">"</span><span class="va">$LOG_DIR</span><span class="st">/pipeline.log"</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="kw">}</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Process CSV files</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu">process_files()</span> <span class="kw">{</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> file <span class="kw">in</span> <span class="st">"</span><span class="va">$DATA_DIR</span><span class="st">"</span>/<span class="pp">*</span>.csv<span class="kw">;</span> <span class="cf">do</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">[</span> <span class="ot">-f</span> <span class="st">"</span><span class="va">$file</span><span class="st">"</span> <span class="bu">]</span><span class="kw">;</span> <span class="cf">then</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>            <span class="va">filename</span><span class="op">=</span><span class="va">$(</span><span class="fu">basename</span> <span class="st">"</span><span class="va">$file</span><span class="st">"</span><span class="va">)</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>            <span class="ex">log_message</span> <span class="st">"Processing </span><span class="va">$filename</span><span class="st">"</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Run Python processing script</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>            <span class="ex">python3</span> /scripts/process_data.py <span class="st">"</span><span class="va">$file</span><span class="st">"</span> <span class="st">"</span><span class="va">$PROCESSED_DIR</span><span class="st">/</span><span class="va">$filename</span><span class="st">"</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">[</span> <span class="va">$?</span> <span class="ot">-eq</span> 0 <span class="bu">]</span><span class="kw">;</span> <span class="cf">then</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                <span class="ex">log_message</span> <span class="st">"Successfully processed </span><span class="va">$filename</span><span class="st">"</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                <span class="fu">mv</span> <span class="st">"</span><span class="va">$file</span><span class="st">"</span> <span class="st">"</span><span class="va">$DATA_DIR</span><span class="st">/archive/"</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>                <span class="ex">log_message</span> <span class="st">"Error processing </span><span class="va">$filename</span><span class="st">"</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">fi</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">fi</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">done</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="kw">}</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="ex">process_files</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="phase-2-big-data-and-advanced-tools-days-14-23" class="level3">
<h3 class="anchored" data-anchor-id="phase-2-big-data-and-advanced-tools-days-14-23">Phase 2: Big Data and Advanced Tools (Days 14-23)</h3>
<section id="big-data-and-hadoop-days-14-16" class="level4">
<h4 class="anchored" data-anchor-id="big-data-and-hadoop-days-14-16">Big Data and Hadoop (Days 14-16)</h4>
<ul>
<li><strong>Day 14</strong>: Big Data concepts, Hadoop, HDFS, MapReduce</li>
<li><strong>Day 15</strong>: Hadoop ecosystem (Pig, Hive, HBase), SQL queries in Big Data</li>
<li><strong>Day 16</strong>: Data modeling, Data Warehouse, normalization/denormalization</li>
</ul>
</section>
<section id="data-pipelines-with-apache-airflow-days-17-20" class="level4">
<h4 class="anchored" data-anchor-id="data-pipelines-with-apache-airflow-days-17-20">Data Pipelines with Apache Airflow (Days 17-20)</h4>
<ul>
<li><strong>Day 17</strong>: Pipeline introduction, Apache Airflow, DAGs</li>
<li><strong>Day 18</strong>: Connections, variables, operators, database integration</li>
<li><strong>Day 19</strong>: <strong>Practice</strong>: DAG for daily Python script execution</li>
<li><strong>Day 20</strong>: <strong>Project</strong>: Simple ETL flow with Airflow</li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Airflow DAG for ETL pipeline</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> airflow <span class="im">import</span> DAG</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> airflow.operators.python_operator <span class="im">import</span> PythonOperator</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime, timedelta</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>default_args <span class="op">=</span> {</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'owner'</span>: <span class="st">'data-team'</span>,</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'depends_on_past'</span>: <span class="va">False</span>,</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'start_date'</span>: datetime(<span class="dv">2024</span>, <span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'email_on_failure'</span>: <span class="va">True</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'email_on_retry'</span>: <span class="va">False</span>,</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'retries'</span>: <span class="dv">2</span>,</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'retry_delay'</span>: timedelta(minutes<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_data(<span class="op">**</span>context):</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Extract data from source"""</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Implementation here</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> transform_data(<span class="op">**</span>context):</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Transform extracted data"""</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Implementation here</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(<span class="op">**</span>context):</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Load data to destination"""</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Implementation here</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>dag <span class="op">=</span> DAG(</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">'daily_etl_pipeline'</span>,</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>    default_args<span class="op">=</span>default_args,</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    description<span class="op">=</span><span class="st">'Daily ETL pipeline'</span>,</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    schedule_interval<span class="op">=</span><span class="st">'@daily'</span>,</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    catchup<span class="op">=</span><span class="va">False</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>extract_task <span class="op">=</span> PythonOperator(</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>    task_id<span class="op">=</span><span class="st">'extract_data'</span>,</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>    python_callable<span class="op">=</span>extract_data,</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>    dag<span class="op">=</span>dag</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>transform_task <span class="op">=</span> PythonOperator(</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>    task_id<span class="op">=</span><span class="st">'transform_data'</span>,</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>    python_callable<span class="op">=</span>transform_data,</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>    dag<span class="op">=</span>dag</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>load_task <span class="op">=</span> PythonOperator(</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>    task_id<span class="op">=</span><span class="st">'load_data'</span>,</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>    python_callable<span class="op">=</span>load_data,</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>    dag<span class="op">=</span>dag</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Set task dependencies</span></span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>extract_task <span class="op">&gt;&gt;</span> transform_task <span class="op">&gt;&gt;</span> load_task</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="apache-spark-days-21-23" class="level4">
<h4 class="anchored" data-anchor-id="apache-spark-days-21-23">Apache Spark (Days 21-23)</h4>
<ul>
<li><strong>Day 21</strong>: Spark architecture, installation, RDDs, DataFrames</li>
<li><strong>Day 22</strong>: DataFrame operations, Spark SQL</li>
<li><strong>Day 23</strong>: <strong>Practice</strong>: CSV file processing with Spark</li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Spark DataFrame operations</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> col, <span class="bu">sum</span>, avg, when, isnan, count</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize Spark Session</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder <span class="op">\</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    .appName(<span class="st">"DataProcessing"</span>) <span class="op">\</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    .config(<span class="st">"spark.sql.adaptive.enabled"</span>, <span class="st">"true"</span>) <span class="op">\</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    .getOrCreate()</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Read data</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.read.option(<span class="st">"header"</span>, <span class="st">"true"</span>).csv(<span class="st">"path/to/data.csv"</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Data quality checks</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> data_quality_report(df):</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Generate data quality report"""</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    total_rows <span class="op">=</span> df.count()</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    quality_report <span class="op">=</span> df.select([</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        count(when(isnan(c) <span class="op">|</span> col(c).isNull(), c)).alias(c <span class="op">+</span> <span class="st">"_nulls"</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> c <span class="kw">in</span> df.columns</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    ]).collect()[<span class="dv">0</span>].asDict()</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'total_rows'</span>: total_rows,</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'null_counts'</span>: quality_report</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformations</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>processed_df <span class="op">=</span> df <span class="op">\</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">filter</span>(col(<span class="st">"amount"</span>) <span class="op">&gt;</span> <span class="dv">0</span>) <span class="op">\</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">"amount_category"</span>, </span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>                when(col(<span class="st">"amount"</span>) <span class="op">&lt;</span> <span class="dv">100</span>, <span class="st">"low"</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>                .when(col(<span class="st">"amount"</span>) <span class="op">&lt;</span> <span class="dv">1000</span>, <span class="st">"medium"</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>                .otherwise(<span class="st">"high"</span>)) <span class="op">\</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    .groupBy(<span class="st">"category"</span>, <span class="st">"amount_category"</span>) <span class="op">\</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    .agg(</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>        <span class="bu">sum</span>(<span class="st">"amount"</span>).alias(<span class="st">"total_amount"</span>),</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        avg(<span class="st">"amount"</span>).alias(<span class="st">"avg_amount"</span>),</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        count(<span class="st">"*"</span>).alias(<span class="st">"transaction_count"</span>)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Write results</span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>processed_df.write <span class="op">\</span></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>    .mode(<span class="st">"overwrite"</span>) <span class="op">\</span></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>    .parquet(<span class="st">"path/to/output"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="phase-3-intermediate-projects-days-24-32" class="level3">
<h3 class="anchored" data-anchor-id="phase-3-intermediate-projects-days-24-32">Phase 3: Intermediate Projects (Days 24-32)</h3>
<section id="specialized-practical-projects" class="level4">
<h4 class="anchored" data-anchor-id="specialized-practical-projects">Specialized Practical Projects</h4>
<p><strong>Day 24: Advanced SQL Project</strong> - Complex database design with multiple related tables - Implementation of complex queries with subqueries and CTEs - Query optimization with indexes and execution plan analysis - Creation of views, stored procedures, and triggers</p>
<p><strong>Day 25: Enterprise ETL Pipeline</strong> <strong>Objective</strong>: Create pipeline that extracts sales data from multiple sources - <strong>Sources</strong>: CSV files, relational databases, REST APIs - <strong>Transformations</strong>: Cleaning, standardization, data enrichment - <strong>Destination</strong>: Data Warehouse (Google BigQuery/Amazon Redshift) - <strong>Technologies</strong>: Python, pandas, SQL, cloud storage - <strong>Deliverables</strong>: Process documentation, versioned code, quality reports</p>
<p><strong>Day 26: Weather Data Project</strong> <strong>Use case</strong>: Real-time climate analysis system - <strong>Extraction</strong>: Weather API (OpenWeatherMap/Weather API) - <strong>Processing</strong>: Apache Spark for distributed transformations - <strong>Storage</strong>: SQL database optimized for time series - <strong>Features</strong>: Missing data handling, anomaly detection, temporal aggregations - <strong>Deliverables</strong>: Visualization dashboard, automatic alerts</p>
<p><strong>Day 27: Big Data Processing</strong> <strong>Challenge</strong>: Process CSV file &gt;1GB with Apache Spark - <strong>Dataset</strong>: Financial transaction data or server logs - <strong>Operations</strong>: Complex aggregations, multi-criteria filtering - <strong>Optimization</strong>: Partitioning, caching, Spark configuration - <strong>Storage</strong>: Data Warehouse with star schema - <strong>Metrics</strong>: Processing time, memory usage, throughput</p>
<p><strong>Day 28: Enterprise Report Automation</strong> <strong>Complete system</strong>: Automated daily sales reports - <strong>Source</strong>: SQL database with transactional data - <strong>Processing</strong>: Spark for aggregations and complex calculations - <strong>Orchestration</strong>: Apache Airflow for automatic scheduling - <strong>Outputs</strong>: PDF reports, web dashboards, email notifications - <strong>Features</strong>: Error handling, retries, detailed logs</p>
<p><strong>Days 29-32: Development and Refinement</strong> - <strong>Day 29</strong>: Integration of projects into personal portfolio - <strong>Day 30</strong>: Performance and scalability optimization - <strong>Day 31</strong>: Implementation of unit and integration tests - <strong>Day 32</strong>: Technical documentation and project presentations</p>
</section>
</section>
<section id="phase-4-advanced-technologies-days-33-49" class="level3">
<h3 class="anchored" data-anchor-id="phase-4-advanced-technologies-days-33-49">Phase 4: Advanced Technologies (Days 33-49)</h3>
<section id="distributed-systems-and-nosql-days-33-36" class="level4">
<h4 class="anchored" data-anchor-id="distributed-systems-and-nosql-days-33-36">Distributed Systems and NoSQL (Days 33-36)</h4>
<ul>
<li><strong>Day 33</strong>: Distributed computing, distributed system architectures</li>
<li><strong>Day 34</strong>: NoSQL databases (MongoDB, Cassandra), Parquet/ORC formats</li>
<li><strong>Day 35</strong>: <strong>Practice</strong>: Migration of SQL project to NoSQL</li>
<li><strong>Day 36</strong>: <strong>Practice</strong>: Parquet format storage with Spark</li>
</ul>
</section>
<section id="data-governance-and-quality-days-37-40" class="level4">
<h4 class="anchored" data-anchor-id="data-governance-and-quality-days-37-40">Data Governance and Quality (Days 37-40)</h4>
<ul>
<li><strong>Day 37</strong>: Introduction to Data Governance, frameworks and responsibilities</li>
<li><strong>Day 38</strong>: Data Governance Framework</li>
<li><strong>Day 39</strong>: Data quality, Data Profiling, quality dimensions</li>
<li><strong>Day 40</strong>: Data Catalog, metadata management, taxonomies</li>
</ul>
</section>
<section id="web-scraping-days-41-49" class="level4">
<h4 class="anchored" data-anchor-id="web-scraping-days-41-49">Web Scraping (Days 41-49)</h4>
<p><strong>Fundamentals and Tools (Days 41-44)</strong> - <strong>Days 41-42</strong>: HTML/CSS, BeautifulSoup, Scrapy, form and session handling - <strong>Day 43</strong>: Data cleaning, cookie and session management, JavaScript handling - <strong>Day 44</strong>: Intelligent crawling, detection evasion, legal and ethical considerations</p>
<p><strong>Practical Web Scraping Projects (Days 45-49)</strong></p>
<p><strong>Day 45: E-commerce Price Monitor</strong> <strong>Project</strong>: Product price monitoring system - <strong>Objective</strong>: Extract prices from multiple e-commerce sites - <strong>Technologies</strong>: Scrapy, requests, BeautifulSoup, pandas - <strong>Features</strong>: - Handle different HTML structures - User agent and proxy rotation - Price history storage - Change detection and alerts - <strong>Deliverables</strong>: Price database, trend dashboard</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Price monitoring scraper</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scrapy</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scrapy.http <span class="im">import</span> Request</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PriceSpider(scrapy.Spider):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    name <span class="op">=</span> <span class="st">'price_monitor'</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, products_file<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.products <span class="op">=</span> pd.read_csv(products_file)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> start_requests(<span class="va">self</span>):</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _, product <span class="kw">in</span> <span class="va">self</span>.products.iterrows():</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> Request(</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>                url<span class="op">=</span>product[<span class="st">'url'</span>],</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>                callback<span class="op">=</span><span class="va">self</span>.parse_price,</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>                meta<span class="op">=</span>{<span class="st">'product_id'</span>: product[<span class="st">'id'</span>], <span class="st">'name'</span>: product[<span class="st">'name'</span>]}</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> parse_price(<span class="va">self</span>, response):</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract price using CSS selectors</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        price_text <span class="op">=</span> response.css(<span class="st">'.price::text'</span>).get()</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> price_text:</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>            price <span class="op">=</span> <span class="bu">float</span>(price_text.replace(<span class="st">'$'</span>, <span class="st">''</span>).replace(<span class="st">','</span>, <span class="st">''</span>))</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> {</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>                <span class="st">'product_id'</span>: response.meta[<span class="st">'product_id'</span>],</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>                <span class="st">'product_name'</span>: response.meta[<span class="st">'name'</span>],</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>                <span class="st">'price'</span>: price,</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>                <span class="st">'url'</span>: response.url,</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>                <span class="st">'scraped_at'</span>: datetime.now(),</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>                <span class="st">'availability'</span>: response.css(<span class="st">'.availability::text'</span>).get()</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>            }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Day 46: News Aggregator System</strong> <strong>Project</strong>: Automatic news aggregator - <strong>Objective</strong>: Monitor multiple news sites and extract headlines - <strong>Functionalities</strong>: - Extract headlines, dates, categories - Automatic topic classification - Duplicate news detection - RSS feed integration - <strong>Technologies</strong>: Scrapy spiders, basic NLP, cron scheduling - <strong>Deliverables</strong>: News API, trend dashboard</p>
<p><strong>Days 47-49: Advanced Projects</strong> - <strong>Day 47</strong>: <strong>Social Media Analytics</strong>: Public social media data scraper - <strong>Day 48</strong>: <strong>Real Estate Monitor</strong>: Property monitoring system - <strong>Day 49</strong>: <strong>Job Market Analysis</strong>: Job posting extraction for market analysis</p>
</section>
</section>
<section id="phase-5-cloud-computing-days-50-57" class="level3">
<h3 class="anchored" data-anchor-id="phase-5-cloud-computing-days-50-57">Phase 5: Cloud Computing (Days 50-57)</h3>
<section id="cloud-platforms-days-50-57" class="level4">
<h4 class="anchored" data-anchor-id="cloud-platforms-days-50-57">Cloud Platforms (Days 50-57)</h4>
<p><strong>Services covered:</strong> - <strong>AWS</strong>: S3, Lambda, Redshift, Kinesis, EMR, Glue, RDS - <strong>Google Cloud</strong>: BigQuery, Dataflow, Dataproc, Cloud Storage, Pub/Sub<br>
- <strong>Azure</strong>: Data Lake, SQL Database, Stream Analytics, HDInsight</p>
<p><strong>Objectives:</strong> - Design scalable infrastructures - Distributed storage - Real-time and batch processing</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: AWS S3 data processing with Lambda</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> boto3</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> io <span class="im">import</span> StringIO</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lambda_handler(event, context):</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Process CSV files uploaded to S3"""</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    s3_client <span class="op">=</span> boto3.client(<span class="st">'s3'</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get bucket and key from event</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    bucket <span class="op">=</span> event[<span class="st">'Records'</span>][<span class="dv">0</span>][<span class="st">'s3'</span>][<span class="st">'bucket'</span>][<span class="st">'name'</span>]</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    key <span class="op">=</span> event[<span class="st">'Records'</span>][<span class="dv">0</span>][<span class="st">'s3'</span>][<span class="st">'object'</span>][<span class="st">'key'</span>]</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Read CSV from S3</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> s3_client.get_object(Bucket<span class="op">=</span>bucket, Key<span class="op">=</span>key)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        csv_content <span class="op">=</span> response[<span class="st">'Body'</span>].read().decode(<span class="st">'utf-8'</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Process with pandas</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> pd.read_csv(StringIO(csv_content))</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Data transformations</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        processed_df <span class="op">=</span> df.groupby(<span class="st">'category'</span>).agg({</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>            <span class="st">'amount'</span>: [<span class="st">'sum'</span>, <span class="st">'mean'</span>, <span class="st">'count'</span>],</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>            <span class="st">'date'</span>: [<span class="st">'min'</span>, <span class="st">'max'</span>]</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        }).<span class="bu">round</span>(<span class="dv">2</span>)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Save processed data</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        output_key <span class="op">=</span> <span class="ss">f"processed/</span><span class="sc">{</span>key<span class="sc">.</span>replace(<span class="st">'.csv'</span>, <span class="st">'_processed.csv'</span>)<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        s3_client.put_object(</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>            Bucket<span class="op">=</span>bucket,</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>            Key<span class="op">=</span>output_key,</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>            Body<span class="op">=</span>processed_df.to_csv(index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>            <span class="st">'statusCode'</span>: <span class="dv">200</span>,</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>            <span class="st">'body'</span>: json.dumps(<span class="ss">f'Successfully processed </span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>            <span class="st">'statusCode'</span>: <span class="dv">500</span>,</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>            <span class="st">'body'</span>: json.dumps(<span class="ss">f'Error processing </span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="bu">str</span>(e)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>        }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="data-streaming---specialized-projects-days-58-71" class="level4">
<h4 class="anchored" data-anchor-id="data-streaming---specialized-projects-days-58-71">Data Streaming - Specialized Projects (Days 58-71)</h4>
<p><strong>Streaming Fundamentals (Days 58-63)</strong> <strong>Tools</strong>: Apache Kafka, Apache Flink, Apache Storm, AWS Kinesis, Google Dataflow</p>
<p><strong>Key concepts</strong>: - Real-time vs batch data processing - Event-driven architectures and microservices - Windowing and temporal aggregations - Exactly-once processing and fault tolerance</p>
<p><strong>Days 64-67: Project 1 - Real-time Log Analysis System</strong> <strong>Use case</strong>: Enterprise web application monitoring</p>
<p><strong>Day 64: Architecture and Setup</strong> - Apache Kafka configuration as message broker - Apache Flink setup for stream processing - Elasticsearch configuration for storage - Pipeline design: Logs â†’ Kafka â†’ Flink â†’ Elasticsearch</p>
<p><strong>Day 65: Ingestion and Processing</strong> - Implementation of producers for sending logs to Kafka - Development of Flink jobs for: - Log filtering by severity - Time window aggregations - Anomaly pattern detection - Data enrichment</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Kafka producer for log streaming</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> kafka <span class="im">import</span> KafkaProducer</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LogProducer:</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, bootstrap_servers<span class="op">=</span>[<span class="st">'localhost:9092'</span>]):</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.producer <span class="op">=</span> KafkaProducer(</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>            bootstrap_servers<span class="op">=</span>bootstrap_servers,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>            value_serializer<span class="op">=</span><span class="kw">lambda</span> v: json.dumps(v).encode(<span class="st">'utf-8'</span>),</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>            key_serializer<span class="op">=</span><span class="kw">lambda</span> k: k.encode(<span class="st">'utf-8'</span>) <span class="cf">if</span> k <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> send_log(<span class="va">self</span>, log_level, message, service_name, user_id<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Send log message to Kafka topic"""</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        log_entry <span class="op">=</span> {</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">'timestamp'</span>: datetime.utcnow().isoformat(),</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">'level'</span>: log_level,</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>            <span class="st">'message'</span>: message,</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>            <span class="st">'service'</span>: service_name,</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>            <span class="st">'user_id'</span>: user_id</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        topic <span class="op">=</span> <span class="ss">f"logs-</span><span class="sc">{</span>log_level<span class="sc">.</span>lower()<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>        key <span class="op">=</span> service_name</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.producer.send(topic, value<span class="op">=</span>log_entry, key<span class="op">=</span>key)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.producer.flush()</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>            logging.error(<span class="ss">f"Failed to send log: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Day 66: Alerts and Monitoring</strong> - Real-time alert system for critical errors - Real-time dashboard with Grafana - Performance metrics implementation - Automatic notification configuration</p>
<p><strong>Day 67: Optimization and Testing</strong> - Load testing with massive log generation - Throughput and latency optimization - Backpressure handling implementation - System documentation</p>
<p><strong>Days 68-71: Project 2 - Real-time Trading Platform</strong> <strong>Use case</strong>: Financial analysis system for algorithmic trading</p>
<p><strong>Day 68: Financial Data Ingestion</strong> - Integration with financial data APIs (Alpha Vantage, Yahoo Finance) - Kafka configuration for price streaming - Schema registry implementation for data evolution - Multiple topics setup per financial instrument</p>
<p><strong>Day 69: Trading Signal Processing</strong> - Real-time technical indicators implementation: - Moving averages (SMA, EMA) - RSI, MACD, Bollinger Bands - Trading pattern detection - Real-time risk calculation</p>
<p><strong>Day 70: Alert and Execution System</strong> - Buy/sell signal generation - Push alert system for opportunities - Order execution simulation - Portfolio performance tracking</p>
<p><strong>Day 71: Dashboard and Analysis</strong> - Interactive dashboard with real-time visualizations - Trading system performance metrics - Latency and throughput analysis - Simulated profitability reports</p>
<p><strong>Technologies used in both projects</strong>: - <strong>Message Brokers</strong>: Apache Kafka, AWS Kinesis - <strong>Stream Processing</strong>: Apache Flink, Apache Storm - <strong>Storage</strong>: Elasticsearch, InfluxDB, AWS S3 - <strong>Visualization</strong>: Grafana, custom dashboards - <strong>Monitoring</strong>: Prometheus, custom metrics</p>
</section>
</section>
<section id="phase-7-final-project-days-72-100" class="level3">
<h3 class="anchored" data-anchor-id="phase-7-final-project-days-72-100">Phase 7: Final Project (Days 72-100)</h3>
<section id="capstone-project---complete-etl-pipeline-days-72-100" class="level4">
<h4 class="anchored" data-anchor-id="capstone-project---complete-etl-pipeline-days-72-100">Capstone Project - Complete ETL Pipeline (Days 72-100)</h4>
<p><strong>Objective</strong>: Develop an end-to-end data pipeline that solves a real business problem.</p>
<section id="strategic-planning-days-72-75" class="level5">
<h5 class="anchored" data-anchor-id="strategic-planning-days-72-75">Strategic Planning (Days 72-75)</h5>
<p><strong>Day 72: Problem Identification and Objective Definition</strong> - Select a real use case (sales optimization, log analysis, real-time processing) - Define SMART project objectives - Identify success metrics and KPIs - Document the business problem to solve</p>
<p><strong>Day 73: Pipeline Architecture Design</strong> - Create high-level architecture diagram - Define data flow: sources â†’ transformation â†’ storage â†’ consumption - Select technology stack (Python, Spark, Airflow, Cloud) - Design data schema and storage structure</p>
<p><strong>Day 74: Data Source Definition</strong> - Identify and catalog all data sources - Evaluate APIs, databases, CSV files, logs - Search for public datasets or generate simulated data if necessary - Document structure and format of each source</p>
<p><strong>Day 75: Infrastructure Configuration</strong> - <strong>Cloud</strong>: Configure AWS/GCP/Azure (S3/GCS, EMR/Dataproc, Redshift/BigQuery) - <strong>Local</strong>: Configure virtual environment with Python, Spark, Airflow - Establish connections between services - Configure security and permissions</p>
</section>
<section id="environment-setup-days-76-79" class="level5">
<h5 class="anchored" data-anchor-id="environment-setup-days-76-79">Environment Setup (Days 76-79)</h5>
<p><strong>Day 76: Orchestration Configuration</strong> - Install and configure Apache Airflow - Create base DAG for task sequence - Configure connections and environment variables - Establish execution scheduling</p>
<p><strong>Day 77: Database Configuration</strong> - Configure SQL/NoSQL databases for storage - Create necessary schemas and tables - Configure indexes for optimization - Establish backup and recovery policies</p>
<p><strong>Day 78: Version Control and Documentation</strong> - Configure Git repository with proper structure - Create .gitignore and configuration files - Establish code and documentation conventions - Configure basic CI/CD</p>
<p><strong>Day 79: Monitoring Configuration</strong> - Implement detailed logging for each stage - Configure monitoring tools (Prometheus, Grafana) - Establish alerts and notifications - Create pipeline monitoring dashboards</p>
</section>
<section id="etl-development-days-80-90" class="level5">
<h5 class="anchored" data-anchor-id="etl-development-days-80-90">ETL Development (Days 80-90)</h5>
<p><strong>Days 80-82: Data Extraction (Extract)</strong> - <strong>Day 80</strong>: Python extraction script development - <strong>Day 81</strong>: Real-time API consumption implementation - <strong>Day 82</strong>: Initial cleaning and validation of extracted data</p>
<p><strong>Days 83-87: Data Transformation (Transform)</strong> - <strong>Day 83</strong>: Transformation rules definition (aggregations, filtering, normalization) - <strong>Day 84</strong>: Spark/pandas transformation development - <strong>Day 85</strong>: Data quality checks implementation - <strong>Day 86</strong>: Transformation testing and optimization - <strong>Day 87</strong>: Validation with large datasets</p>
<p><strong>Days 88-90: Data Loading (Load)</strong> - <strong>Day 88</strong>: Data Warehouse loading process configuration - <strong>Day 89</strong>: Complete ETL pipeline integration - <strong>Day 90</strong>: Airflow automation and execution scheduling</p>
</section>
<section id="optimization-and-finalization-days-91-100" class="level5">
<h5 class="anchored" data-anchor-id="optimization-and-finalization-days-91-100">Optimization and Finalization (Days 91-100)</h5>
<p><strong>Days 91-93: Optimization and Security</strong> - <strong>Day 91</strong>: SQL query and Spark process optimization - <strong>Day 92</strong>: Security implementation (encryption, RBAC) - <strong>Day 93</strong>: Scalability and performance testing</p>
<p><strong>Days 94-96: Documentation and Visualization</strong> - <strong>Day 94</strong>: Complete pipeline and process documentation - <strong>Day 95</strong>: Dashboard creation with Tableau/Power BI - <strong>Day 96</strong>: Final results report preparation</p>
<p><strong>Days 97-100: Review and Presentation</strong> - <strong>Day 97</strong>: Complete review and error correction - <strong>Day 98</strong>: End-to-end testing - <strong>Day 99</strong>: Final presentation preparation - <strong>Day 100</strong>: Project presentation and final delivery</p>
</section>
</section>
</section>
</section>
<section id="technologies-and-tools-covered" class="level2">
<h2 class="anchored" data-anchor-id="technologies-and-tools-covered">Technologies and Tools Covered</h2>
<section id="programming-languages" class="level3">
<h3 class="anchored" data-anchor-id="programming-languages">Programming Languages</h3>
<ul>
<li><strong>SQL</strong> - Queries, optimization, database management</li>
<li><strong>Python</strong> - Data manipulation, automation, APIs</li>
<li><strong>Bash</strong> - Automation, system administration</li>
</ul>
</section>
<section id="big-data-tools" class="level3">
<h3 class="anchored" data-anchor-id="big-data-tools">Big Data Tools</h3>
<ul>
<li><strong>Apache Hadoop</strong> - HDFS, MapReduce, complete ecosystem</li>
<li><strong>Apache Spark</strong> - Distributed processing, DataFrames, SQL</li>
<li><strong>Apache Airflow</strong> - Pipeline orchestration, DAGs</li>
</ul>
</section>
<section id="databases" class="level3">
<h3 class="anchored" data-anchor-id="databases">Databases</h3>
<ul>
<li><strong>Relational</strong> - MySQL, PostgreSQL, optimization</li>
<li><strong>NoSQL</strong> - MongoDB, Cassandra</li>
<li><strong>Data Warehouses</strong> - BigQuery, Redshift</li>
</ul>
</section>
<section id="cloud-platforms" class="level3">
<h3 class="anchored" data-anchor-id="cloud-platforms">Cloud Platforms</h3>
<ul>
<li><strong>AWS</strong> - S3, EMR, Redshift, Kinesis, Lambda, Glue</li>
<li><strong>Google Cloud</strong> - BigQuery, Dataflow, Dataproc</li>
<li><strong>Microsoft Azure</strong> - Data Lake, Stream Analytics</li>
</ul>
</section>
<section id="streaming-and-real-time" class="level3">
<h3 class="anchored" data-anchor-id="streaming-and-real-time">Streaming and Real-time</h3>
<ul>
<li><strong>Apache Kafka</strong> - Message streaming</li>
<li><strong>Apache Flink</strong> - Stream processing</li>
<li><strong>AWS Kinesis</strong> - Real-time data streaming</li>
</ul>
</section>
</section>
<section id="learning-methodology" class="level2">
<h2 class="anchored" data-anchor-id="learning-methodology">Learning Methodology</h2>
<section id="daily-structure" class="level3">
<h3 class="anchored" data-anchor-id="daily-structure">Daily Structure</h3>
<ol type="1">
<li><strong>Theory</strong> - Fundamental concepts</li>
<li><strong>Guided Practice</strong> - Structured exercises<br>
</li>
<li><strong>Projects</strong> - Practical application</li>
<li><strong>Review</strong> - Knowledge consolidation</li>
</ol>
</section>
<section id="progressive-approach" class="level3">
<h3 class="anchored" data-anchor-id="progressive-approach">Progressive Approach</h3>
<ul>
<li><strong>Weeks 1-2</strong>: Solid fundamentals</li>
<li><strong>Weeks 3-7</strong>: Intermediate tools</li>
<li><strong>Weeks 8-11</strong>: Advanced technologies</li>
<li><strong>Weeks 12-14</strong>: Independent project</li>
</ul>
</section>
<section id="key-components" class="level3">
<h3 class="anchored" data-anchor-id="key-components">Key Components</h3>
<ul>
<li><strong>40% Theory</strong> - Concepts and best practices</li>
<li><strong>35% Practice</strong> - Exercises and labs</li>
<li><strong>25% Projects</strong> - Real application</li>
</ul>
</section>
</section>
<section id="expected-results" class="level2">
<h2 class="anchored" data-anchor-id="expected-results">Expected Results</h2>
<p>Upon completing the 100 days, you will have:</p>
<section id="technical-skills" class="level3">
<h3 class="anchored" data-anchor-id="technical-skills">Technical Skills</h3>
<ul>
<li>SQL mastery for complex data analysis</li>
<li>Python competency for data engineering</li>
<li>Practical experience with Big Data tools</li>
<li>Knowledge of scalable cloud architectures</li>
<li>Ability to design robust ETL pipelines</li>
</ul>
</section>
<section id="portfolio-projects" class="level3">
<h3 class="anchored" data-anchor-id="portfolio-projects">Portfolio Projects</h3>
<p>Upon completing the program, you will have a robust portfolio with diverse projects:</p>
<section id="fundamental-projects" class="level4">
<h4 class="anchored" data-anchor-id="fundamental-projects">Fundamental Projects</h4>
<ul>
<li><strong>Enterprise ETL Pipeline</strong>: Complete system for extracting, transforming, and loading sales data</li>
<li><strong>Advanced SQL Project</strong>: Optimized database with complex queries and stored procedures</li>
<li><strong>Climate Monitoring System</strong>: API integration with distributed Spark processing</li>
</ul>
</section>
<section id="big-data-projects" class="level4">
<h4 class="anchored" data-anchor-id="big-data-projects">Big Data Projects</h4>
<ul>
<li><strong>Massive File Processor</strong>: Handling datasets &gt;1GB with Spark optimizations</li>
<li><strong>Automated Reporting System</strong>: Airflow orchestration for enterprise reports</li>
<li><strong>SQL to NoSQL Migration</strong>: Performance comparison between relational and NoSQL databases</li>
</ul>
</section>
<section id="web-scraping-projects" class="level4">
<h4 class="anchored" data-anchor-id="web-scraping-projects">Web Scraping Projects</h4>
<ul>
<li><strong>E-commerce Price Monitor</strong>: Price monitoring system with automatic alerts</li>
<li><strong>News Aggregator</strong>: News aggregation platform with automatic classification</li>
<li><strong>Real Estate Analytics</strong>: Real estate market analysis with extracted data</li>
</ul>
</section>
<section id="cloud-projects" class="level4">
<h4 class="anchored" data-anchor-id="cloud-projects">Cloud Projects</h4>
<ul>
<li><strong>Multi-Cloud Architecture</strong>: Implementation on AWS, GCP, and Azure with service comparison</li>
<li><strong>Data Lake Implementation</strong>: Distributed storage with serverless processing</li>
<li><strong>Streaming Analytics</strong>: Real-time processing with cloud-native services</li>
</ul>
</section>
<section id="streaming-projects" class="level4">
<h4 class="anchored" data-anchor-id="streaming-projects">Streaming Projects</h4>
<ul>
<li><strong>Log Analysis System</strong>: Real-time monitoring of enterprise applications</li>
<li><strong>Trading Platform</strong>: Financial analysis with real-time technical indicators</li>
<li><strong>IoT Data Pipeline</strong>: Sensor data processing with Apache Kafka and Flink</li>
</ul>
</section>
<section id="capstone-project" class="level4">
<h4 class="anchored" data-anchor-id="capstone-project">Capstone Project</h4>
<ul>
<li><strong>End-to-End ETL Pipeline</strong>: Complete solution integrating all learned technologies</li>
<li><strong>Professional Documentation</strong>: Architecture, code, tests, and performance metrics</li>
<li><strong>Executive Presentation</strong>: Demonstration of business value and project ROI</li>
</ul>
</section>
</section>
<section id="professional-preparation" class="level3">
<h3 class="anchored" data-anchor-id="professional-preparation">Professional Preparation</h3>
<ul>
<li>Knowledge of industry best practices</li>
<li>Experience with standard enterprise tools<br>
</li>
<li>Ability to solve real data problems</li>
<li>Solid foundation for Data Engineer roles</li>
</ul>
</section>
</section>
<section id="success-recommendations" class="level2">
<h2 class="anchored" data-anchor-id="success-recommendations">Success Recommendations</h2>
<section id="consistency" class="level3">
<h3 class="anchored" data-anchor-id="consistency">Consistency</h3>
<ul>
<li>Dedicate daily time to the program</li>
<li>Maintain a sustainable pace</li>
<li>Donâ€™t skip practice sessions</li>
</ul>
</section>
<section id="active-practice" class="level3">
<h3 class="anchored" data-anchor-id="active-practice">Active Practice</h3>
<ul>
<li>Implement all exercises</li>
<li>Experiment beyond requirements</li>
<li>Document your progress</li>
</ul>
</section>
<section id="community" class="level3">
<h3 class="anchored" data-anchor-id="community">Community</h3>
<ul>
<li>Share your projects</li>
<li>Seek feedback from other professionals</li>
<li>Participate in Data Engineering communities</li>
</ul>
</section>
<section id="adaptation" class="level3">
<h3 class="anchored" data-anchor-id="adaptation">Adaptation</h3>
<ul>
<li>Adjust pace according to your availability</li>
<li>Deepen areas of greater interest</li>
<li>Maintain focus on practical objectives</li>
</ul>
<hr>
<p><strong>Total Duration</strong>: 100 days<br>
<strong>Level</strong>: Beginner to Intermediate-Advanced<br>
<strong>Mode</strong>: Self-study with practical projects<br>
<strong>Result</strong>: Complete preparation for Data Engineer roles</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>